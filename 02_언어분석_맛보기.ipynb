{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_언어분석_맛보기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaF87YtGQvK+xl/kMJvbIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhkoreadh/hufs/blob/main/02_%EC%96%B8%EC%96%B4%EB%B6%84%EC%84%9D_%EB%A7%9B%EB%B3%B4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eHLeTgZ96ys",
        "cellView": "form",
        "outputId": "1d61f56d-f5af-4b81-cde8-9a2bca0dc535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "#@title N-Gram - 띄어쓰기 기준 분리\n",
        "문장 = '\\uC6C3\\uC5B4\\uB77C, \\uC628 \\uC138\\uC0C1\\uC774 \\uB108\\uC640 \\uD568\\uAED8 \\uC6C3\\uC744 \\uAC83\\uC774\\uB2E4. \\uC6B8\\uC5B4\\uB77C, \\uB108 \\uD63C\\uC790 \\uC6B8\\uAC83\\uC774\\uB2E4.'  #@param {type: \"string\"}\n",
        "NGram크기 = \"3\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"] {allow-input: true}\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "ngrams = ngrams(문장.split(), int(NGram크기))\n",
        "\n",
        "for grams in ngrams:\n",
        "  print(grams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('웃어라,', '온', '세상이')\n",
            "('온', '세상이', '너와')\n",
            "('세상이', '너와', '함께')\n",
            "('너와', '함께', '웃을')\n",
            "('함께', '웃을', '것이다.')\n",
            "('웃을', '것이다.', '울어라,')\n",
            "('것이다.', '울어라,', '너')\n",
            "('울어라,', '너', '혼자')\n",
            "('너', '혼자', '울것이다.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5sZRTMJafCpf",
        "outputId": "90fea2e8-66a0-4b14-9330-f917b1c94577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "#@title N-Gram - 1글자 기준 분리\n",
        "문장 = '\\u6211\\u7231\\u4F60\\u3002\\u5982\\u679C\\u8981\\u5728\\u4E2A\\u5206\\u611F\\u60C5\\u4E0A\\u52A0\\u4E0A\\u4E00\\u4E2A\\u671F\\u9650\\u7684\\u8BDD\\u6211\\u5E0C\\u671B\\u662F\\u6709\\u4E07\\u5E74\\uFF01'  #@param {type: \"string\"}\n",
        "NGram크기 = \"3\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"] {allow-input: true}\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "ngrams = list(ngrams(문장, int(NGram크기)))\n",
        "\n",
        "for grams in ngrams:\n",
        "  print(grams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('我', '爱', '你')\n",
            "('爱', '你', '。')\n",
            "('你', '。', '如')\n",
            "('。', '如', '果')\n",
            "('如', '果', '要')\n",
            "('果', '要', '在')\n",
            "('要', '在', '个')\n",
            "('在', '个', '分')\n",
            "('个', '分', '感')\n",
            "('分', '感', '情')\n",
            "('感', '情', '上')\n",
            "('情', '上', '加')\n",
            "('上', '加', '上')\n",
            "('加', '上', '一')\n",
            "('上', '一', '个')\n",
            "('一', '个', '期')\n",
            "('个', '期', '限')\n",
            "('期', '限', '的')\n",
            "('限', '的', '话')\n",
            "('的', '话', '我')\n",
            "('话', '我', '希')\n",
            "('我', '希', '望')\n",
            "('希', '望', '是')\n",
            "('望', '是', '有')\n",
            "('是', '有', '万')\n",
            "('有', '万', '年')\n",
            "('万', '年', '！')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnFuSHZj-qLX",
        "cellView": "form",
        "outputId": "48173796-c785-4aee-8918-79a02ac762b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "#@title 한국어 형태소 분석 - konlpy(kkma)\n",
        "한국어문장 = '\\uC6C3\\uC5B4\\uB77C, \\uC628 \\uC138\\uC0C1\\uC774 \\uB108\\uC640 \\uD568\\uAED8 \\uC6C3\\uC744 \\uAC83\\uC774\\uB2E4. \\uC6B8\\uC5B4\\uB77C, \\uB108 \\uD63C\\uC790 \\uC6B8\\uAC83\\uC774\\uB2E4.'  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# konlpy 설치하기 ## https://data1000.tistory.com/33\n",
        "!pip3 install jpype1==0.7.0\n",
        "!pip3 install konlpy\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.utils import pprint\n",
        "kkma = Kkma()\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###문장 분리###\")\n",
        "print(kkma.sentences(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###명사 추출###\")\n",
        "print(kkma.nouns(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###형태소 분리###\")\n",
        "print(kkma.morphs(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###품사 태깅###\")\n",
        "print(kkma.pos(한국어문장))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  \n",
            "###문장 분리###\n",
            "['웃어라,', '온 세상이 너와 함께 웃을 것이다.', '울어 라, 너 혼자 울 것이다.']\n",
            "  \n",
            "###명사 추출###\n",
            "['세상', '너', '라', '혼자']\n",
            "  \n",
            "###형태소 분리###\n",
            "['웃', '어라', ',', '온', '세상', '이', '너', '와', '함께', '웃', '을', '것', '이', '다', '.', '울', '어', '라', ',', '너', '혼자', '울', 'ㄹ', '것', '이', '다', '.']\n",
            "  \n",
            "###품사 태깅###\n",
            "[('웃', 'VV'), ('어라', 'EFO'), (',', 'SP'), ('온', 'MDT'), ('세상', 'NNG'), ('이', 'JKS'), ('너', 'NP'), ('와', 'JKM'), ('함께', 'MAG'), ('웃', 'VV'), ('을', 'ETD'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EFN'), ('.', 'SF'), ('울', 'VV'), ('어', 'ECD'), ('라', 'NNG'), (',', 'SP'), ('너', 'NP'), ('혼자', 'NNG'), ('울', 'VV'), ('ㄹ', 'ETD'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EFN'), ('.', 'SF')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTKbA5BxZ6U",
        "cellView": "form",
        "outputId": "df61c11f-98e2-4f8c-9ac5-0de54faf0764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "#@title 한국어 형태소 분석 - konlpy(okt)\n",
        "한국어문장 = '\\uC6C3\\uC5B4\\uB77C, \\uC628 \\uC138\\uC0C1\\uC774 \\uB108\\uC640 \\uD568\\uAED8 \\uC6C3\\uC744 \\uAC83\\uC774\\uB2E4. \\uC6B8\\uC5B4\\uB77C, \\uB108 \\uD63C\\uC790 \\uC6B8\\uAC83\\uC774\\uB2E4.'  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# konlpy 설치하기 ## https://data1000.tistory.com/33\n",
        "!pip3 install jpype1==0.7.0\n",
        "!pip3 install konlpy\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.utils import pprint\n",
        "okt = Okt()\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###명사 추출###\")\n",
        "print(okt.nouns(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###형태소 분리###\")\n",
        "print(okt.morphs(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###품사 태깅###\")\n",
        "print(okt.pos(한국어문장))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  \n",
            "###명사 추출###\n",
            "['온', '세상', '너', '웃', '것', '너', '혼자']\n",
            "  \n",
            "###형태소 분리###\n",
            "['웃어라', ',', '온', '세상', '이', '너', '와', '함께', '웃', '을', '것', '이다', '.', '울어라', ',', '너', '혼자', '울것이다', '.']\n",
            "  \n",
            "###품사 태깅###\n",
            "[('웃어라', 'Verb'), (',', 'Punctuation'), ('온', 'Noun'), ('세상', 'Noun'), ('이', 'Josa'), ('너', 'Noun'), ('와', 'Josa'), ('함께', 'Adverb'), ('웃', 'Noun'), ('을', 'Josa'), ('것', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation'), ('울어라', 'Verb'), (',', 'Punctuation'), ('너', 'Noun'), ('혼자', 'Noun'), ('울것이다', 'Verb'), ('.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bys2hWtW-8cN",
        "cellView": "form",
        "outputId": "826b1309-b8e3-4609-ff2f-1f5c682fc1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "#@title 중국어 형태소 분석 - Jieba\n",
        "중국어문장 = '\\u6211\\u7231\\u4F60\\u3002\\u5982\\u679C\\u8981\\u5728\\u4E2A\\u5206\\u611F\\u60C5\\u4E0A\\u52A0\\u4E0A\\u4E00\\u4E2A\\u671F\\u9650\\u7684\\u8BDD\\u6211\\u5E0C\\u671B\\u662F\\u6709\\u4E07\\u5E74\\uFF01'  #@param {type: \"string\"}\n",
        "\n",
        "!pip install jieba\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "# encoding=utf-8\n",
        "\n",
        "import jieba\n",
        "\n",
        "seg_list = jieba.cut(중국어문장)  # 默认是精确模式\n",
        "print(\"  \")\n",
        "print(\"###精确模式###\")\n",
        "print(\", \".join(seg_list))\n",
        "\n",
        "seg_list = jieba.cut_for_search(중국어문장)  # 搜索引擎模式\n",
        "print(\"  \")\n",
        "print(\"###搜索引擎模式###\")\n",
        "print(\", \".join(seg_list))\n",
        "\n",
        "import jieba.posseg as pseg\n",
        "words = pseg.cut(중국어문장)\n",
        "print(\"  \")\n",
        "print(\"###词性标注###\")\n",
        "for word, flag in words:\n",
        "  print('%s %s' % (word, flag))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  \n",
            "###精确模式###\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.955 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "我爱你, 。, 如果, 要, 在, 个, 分, 感情, 上, 加上, 一个, 期限, 的话, 我, 希望, 是, 有, 万年, ！\n",
            "  \n",
            "###搜索引擎模式###\n",
            "我爱你, 。, 如果, 要, 在, 个, 分, 感情, 上, 加上, 一个, 期限, 的话, 我, 希望, 是, 有, 万年, ！\n",
            "  \n",
            "###词性标注###\n",
            "我爱你 l\n",
            "。 x\n",
            "如果 c\n",
            "要 v\n",
            "在 p\n",
            "个分 n\n",
            "感情 n\n",
            "上 f\n",
            "加上 v\n",
            "一个 m\n",
            "期限 n\n",
            "的话 u\n",
            "我 r\n",
            "希望 v\n",
            "是 v\n",
            "有 v\n",
            "万年 m\n",
            "！ x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdz0Sd2Mgxtm",
        "cellView": "form",
        "outputId": "a93bc60c-cc37-4d09-ced9-c6013b618912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title 영어 형태소 분석 - NLTK\n",
        "영어문장 = 'Great power always comes with great responsibility.'  #@param {type: \"string\"}\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "영어토큰화 = nltk.tokenize.word_tokenize(영어문장)\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "# encoding=utf-8\n",
        "\n",
        "print(\"  \")\n",
        "print(영어토큰화)\n",
        "\n",
        "print(\"  \")\n",
        "print(nltk.pos_tag(영어토큰화))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  \n",
            "['Great', 'power', 'always', 'comes', 'with', 'great', 'responsibility', '.']\n",
            "  \n",
            "[('Great', 'NNP'), ('power', 'NN'), ('always', 'RB'), ('comes', 'VBZ'), ('with', 'IN'), ('great', 'JJ'), ('responsibility', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}